{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import config\n",
    "from models import load_pipeline\n",
    "from data import RobotKeypointDataset\n",
    "from utils import compute_add_error_ik, compute_auc\n",
    "from utils.kinematics import get_joint_positions\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dirs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "RESULTS_DIR = Path('../results')\n",
    "DATA_DIR = RESULTS_DIR / 'data'\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = load_pipeline(\n",
    "    stage1_path='../checkpoints/stage1_best.pt',\n",
    "    stage2_path='../checkpoints/stage2_best.pt',\n",
    "    config=config,\n",
    "    device=device\n",
    ")\n",
    "print(\"pipeline loaded\")\n",
    "\n",
    "test_dataset = RobotKeypointDataset(\n",
    "    data_dirs=[config.TEST_DIR],\n",
    "    config=config,\n",
    "    load_3d=True,\n",
    "    load_angles=True\n",
    ")\n",
    "print(f\"Test set {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rows = []\n",
    "inference_times = []\n",
    "\n",
    "for i in tqdm(range(len(test_dataset)), desc=\"Evaluating\"):\n",
    "    sample = test_dataset.samples[i]\n",
    "    img_path = sample['img_path']\n",
    "    gt_2d = sample['keypoints']  # shape 6, 2\n",
    "    gt_3d = sample.get('positions_3d')  # shape 6, 3\n",
    "    gt_angles_deg = sample.get('joint_angles')  # in deg\n",
    "    \n",
    "    gt_bbox = test_dataset.compute_bbox(gt_2d)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pred_2d, pred_bbox = pipeline.predict(img_path)\n",
    "    inference_time = time.time() - start_time\n",
    "    inference_times.append(inference_time)\n",
    "    \n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    pred_2d_gt_bbox = pipeline.predict_with_gt_bbox(img, gt_bbox)\n",
    "    \n",
    "    errors_2d_full = np.linalg.norm(pred_2d - gt_2d, axis=1)\n",
    "    errors_2d_gt_bbox = np.linalg.norm(pred_2d_gt_bbox - gt_2d, axis=1)\n",
    "    \n",
    "    row = {\n",
    "        'sample_idx': i,\n",
    "        'img_path': img_path,\n",
    "        'inference_time_ms': inference_time * 1000,\n",
    "        # Bboxes\n",
    "        'gt_bbox_xmin': gt_bbox[0],\n",
    "        'gt_bbox_ymin': gt_bbox[1],\n",
    "        'gt_bbox_xmax': gt_bbox[2],\n",
    "        'gt_bbox_ymax': gt_bbox[3],\n",
    "        'pred_bbox_xmin': pred_bbox[0],\n",
    "        'pred_bbox_ymin': pred_bbox[1],\n",
    "        'pred_bbox_xmax': pred_bbox[2],\n",
    "        'pred_bbox_ymax': pred_bbox[3],\n",
    "        # Mean 2D errors\n",
    "        'mean_2d_error_px': errors_2d_full.mean(),\n",
    "        'mean_2d_error_gt_bbox_px': errors_2d_gt_bbox.mean(),\n",
    "    }\n",
    "    \n",
    "    # per-joint 2D data\n",
    "    for j, joint_name in enumerate(config.JOINT_NAMES):\n",
    "        row[f'gt_{joint_name}_x'] = gt_2d[j, 0]\n",
    "        row[f'gt_{joint_name}_y'] = gt_2d[j, 1]\n",
    "        row[f'pred_{joint_name}_x'] = pred_2d[j, 0]\n",
    "        row[f'pred_{joint_name}_y'] = pred_2d[j, 1]\n",
    "        row[f'error_2d_{joint_name}_px'] = errors_2d_full[j]\n",
    "        if gt_3d is not None:\n",
    "            row[f'gt_3d_{joint_name}_x'] = gt_3d[j, 0]\n",
    "            row[f'gt_3d_{joint_name}_y'] = gt_3d[j, 1]\n",
    "            row[f'gt_3d_{joint_name}_z'] = gt_3d[j, 2]\n",
    "        if gt_angles_deg is not None:\n",
    "            row[f'gt_angle_J{j}_deg'] = gt_angles_deg[j]\n",
    "    \n",
    "    results_rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(results_rows)\n",
    "\n",
    "inference_times = np.array(inference_times)\n",
    "print(f\"\\ninference timing\")\n",
    "print(f\"mean: {inference_times.mean()*1000:.1f} ms\")\n",
    "print(f\"std: {inference_times.std()*1000:.1f} ms\")\n",
    "print(f\"fps: {1/inference_times.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ik-header",
   "metadata": {},
   "source": [
    "## IK Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ik-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_angles = any(f'gt_angle_J{i}_deg' in df.columns for i in range(6))\n",
    "has_3d = 'gt_3d_Base_x' in df.columns\n",
    "\n",
    "if has_angles and has_3d:    \n",
    "    ik_results = {'add_ik': [], 'angle_errors': [], 'reproj_errors': [], 'est_angles': []}\n",
    "    \n",
    "    for i in tqdm(range(len(df)), desc=\"IK Evaluation\"):\n",
    "        sample = test_dataset.samples[i]\n",
    "        pred_2d = np.array([[df.loc[i, f'pred_{jn}_x'], df.loc[i, f'pred_{jn}_y']] \n",
    "                           for jn in config.JOINT_NAMES])\n",
    "        gt_2d = sample['keypoints']\n",
    "        gt_3d = sample['positions_3d']\n",
    "        gt_angles_deg = sample['joint_angles']\n",
    "        \n",
    "        try:\n",
    "            add_error, per_joint_3d, angle_errors_deg, reproj_error = compute_add_error_ik(\n",
    "                pred_2d, gt_2d, gt_3d, gt_angles_deg, config.CAMERA_MATRIX\n",
    "            )\n",
    "            from utils.kinematics import solve_ik_from_2d\n",
    "            est_angles_deg, est_3d, _ = solve_ik_from_2d(\n",
    "                pred_2d, gt_2d, gt_3d, gt_angles_deg, config.CAMERA_MATRIX\n",
    "            )\n",
    "            ik_results['add_ik'].append(add_error)\n",
    "            ik_results['angle_errors'].append(angle_errors_deg)\n",
    "            ik_results['reproj_errors'].append(reproj_error)\n",
    "            ik_results['est_angles'].append(est_angles_deg)\n",
    "        except:\n",
    "            ik_results['add_ik'].append(np.nan)\n",
    "            ik_results['angle_errors'].append(np.full(6, np.nan))\n",
    "            ik_results['reproj_errors'].append(np.nan)\n",
    "            ik_results['est_angles'].append(np.full(6, np.nan))\n",
    "    \n",
    "    df['add_ik_m'] = ik_results['add_ik']\n",
    "    df['add_ik_cm'] = np.array(ik_results['add_ik']) * 100\n",
    "    df['ik_reproj_error_px'] = ik_results['reproj_errors']\n",
    "    \n",
    "    angle_errors = np.array(ik_results['angle_errors'])\n",
    "    est_angles_all = np.array(ik_results['est_angles'])\n",
    "    for j, jn in enumerate(config.JOINT_NAMES):\n",
    "        df[f'angle_error_{jn}_deg'] = angle_errors[:, j]\n",
    "        df[f'est_angle_J{j}_deg'] = est_angles_all[:, j]\n",
    "    \n",
    "    add_ik = np.array(ik_results['add_ik'])\n",
    "    valid = ~np.isnan(add_ik)\n",
    "    print(f\"\\nIK results ({valid.sum()}/{len(add_ik)} valid):\")\n",
    "    print(f\"mean ADD Error: {np.nanmean(add_ik)*100:.2f} cm\")\n",
    "    print(f\"median ADD Error: {np.nanmedian(add_ik)*100:.2f} cm\")\n",
    "    print(f\"\\nper joint angle errors (degreees):\")\n",
    "    for j, jn in enumerate(config.JOINT_NAMES):\n",
    "        print(f\"  {jn}: {np.nanmean(angle_errors[:, j]):.2f}°\")\n",
    "else:\n",
    "    print(\"missing GT angle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_DIR / 'predictions.csv', index=False, float_format='%.6f')\n",
    "print(f\"Saved: {DATA_DIR / 'predictions.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_errors = df['mean_2d_error_px'].values\n",
    "pixel_errors_gt = df['mean_2d_error_gt_bbox_px'].values\n",
    "\n",
    "add_ik = df['add_ik_m'].dropna().values\n",
    "\n",
    "auc_ik, thresholds, acc_ik = compute_auc(add_ik, max_threshold=0.30, num_steps=100)\n",
    "\n",
    "summary = {\n",
    "    'Metric': [\n",
    "        'Mean 2D Error (px)',\n",
    "        'Median 2D Error (px)',\n",
    "        'Std 2D Error (px)',\n",
    "        'Mean ADD Error (cm)',\n",
    "        'Median ADD Error (cm)',\n",
    "        'Std ADD Error (cm)',\n",
    "        'AUC (0-30cm)',\n",
    "        'Accuracy @5cm (%)',\n",
    "        'Accuracy @10cm (%)',\n",
    "        'Accuracy @20cm (%)',\n",
    "        'Mean Inference Time (ms)',\n",
    "        'FPS',\n",
    "    ],\n",
    "    'Full Pipeline': [\n",
    "        f\"{pixel_errors.mean():.2f}\",\n",
    "        f\"{np.median(pixel_errors):.2f}\",\n",
    "        f\"{pixel_errors.std():.2f}\",\n",
    "        f\"{add_ik.mean() * 100:.2f}\",\n",
    "        f\"{np.median(add_ik) * 100:.2f}\",\n",
    "        f\"{add_ik.std() * 100:.2f}\",\n",
    "        f\"{auc_ik:.3f}\",\n",
    "        f\"{(add_ik <= 0.05).mean() * 100:.1f}\",\n",
    "        f\"{(add_ik <= 0.10).mean() * 100:.1f}\",\n",
    "        f\"{(add_ik <= 0.20).mean() * 100:.1f}\",\n",
    "        f\"{inference_times.mean()*1000:.1f}\",\n",
    "        f\"{1/inference_times.mean():.1f}\",\n",
    "    ],\n",
    "    'GT BBox (Stage 2 only)': [\n",
    "        f\"{pixel_errors_gt.mean():.2f}\",\n",
    "        f\"{np.median(pixel_errors_gt):.2f}\",\n",
    "        f\"{pixel_errors_gt.std():.2f}\",\n",
    "        '-', '-', '-', '-', '-', '-', '-', '-', '-'\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "df_summary.to_csv(DATA_DIR / 'summary_metrics.csv', index=False)\n",
    "\n",
    "df_auc = pd.DataFrame({\n",
    "    'threshold_cm': thresholds * 100,\n",
    "    'accuracy_pct': acc_ik * 100,\n",
    "})\n",
    "\n",
    "\n",
    "df_auc.to_csv(DATA_DIR / 'auc_curve_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "per-joint-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per joint error summary\n",
    "joint_summary = []\n",
    "for j, jn in enumerate(config.JOINT_NAMES):\n",
    "    row = {\n",
    "        'Joint': jn,\n",
    "        'Mean 2D (px)': df[f'error_2d_{jn}_px'].mean(),\n",
    "        'Std 2D (px)': df[f'error_2d_{jn}_px'].std(),\n",
    "    }\n",
    "    if f'angle_error_{jn}_deg' in df.columns:\n",
    "        row['Mean Angle Error (°)'] = df[f'angle_error_{jn}_deg'].mean()\n",
    "        row['Std Angle Error (°)'] = df[f'angle_error_{jn}_deg'].std()\n",
    "    joint_summary.append(row)\n",
    "\n",
    "df_joints = pd.DataFrame(joint_summary)\n",
    "print(\"per joint errors\")\n",
    "print(df_joints.to_string(index=False))\n",
    "\n",
    "df_joints.to_csv(DATA_DIR / 'per_joint_errors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 3D Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction_3d(sample_idx, df, test_dataset, save_path=None):\n",
    "    sample = test_dataset.samples[sample_idx]\n",
    "    img = Image.open(sample['img_path'])\n",
    "    gt_2d = sample['keypoints']\n",
    "    gt_3d = sample['positions_3d']\n",
    "    gt_angles_deg = sample['joint_angles']\n",
    "    \n",
    "    pred_2d = np.array([[df.loc[sample_idx, f'pred_{jn}_x'], df.loc[sample_idx, f'pred_{jn}_y']] \n",
    "                       for jn in config.JOINT_NAMES])\n",
    "    \n",
    "    if f'est_angle_J0_deg' in df.columns:\n",
    "        est_angles_deg = np.array([df.loc[sample_idx, f'est_angle_J{j}_deg'] for j in range(6)])\n",
    "        est_3d = get_joint_positions(est_angles_deg, include_base=True, angles_in_radians=False)\n",
    "    else:\n",
    "        est_3d = gt_3d \n",
    "    \n",
    "    connections = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n",
    "    \n",
    "    gt_color = '#2ecc71'\n",
    "    pred_color = '#e74c3c'\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.imshow(img)\n",
    "    \n",
    "    ax1.scatter(gt_2d[:, 0], gt_2d[:, 1], c=gt_color, s=100, marker='o', \n",
    "                label='Ground Truth', edgecolors='white', linewidths=2, zorder=5) #gt keypoints\n",
    "    ax1.scatter(pred_2d[:, 0], pred_2d[:, 1], c=pred_color, s=100, marker='x', # predicted keypoints\n",
    "                label='Predicted', linewidths=3, zorder=5)\n",
    "    \n",
    "    for i, j in connections:\n",
    "        ax1.plot([gt_2d[i, 0], gt_2d[j, 0]], [gt_2d[i, 1], gt_2d[j, 1]], \n",
    "                 c=gt_color, linewidth=2, alpha=0.7)\n",
    "        ax1.plot([pred_2d[i, 0], pred_2d[j, 0]], [pred_2d[i, 1], pred_2d[j, 1]], \n",
    "                 c=pred_color, linewidth=2, alpha=0.7, linestyle='--')\n",
    "    \n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_title(f'2D Keypoints (Error: {df.loc[sample_idx, \"mean_2d_error_px\"]:.1f} px)')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    \n",
    "    ax2.scatter(gt_3d[:, 0], gt_3d[:, 1], gt_3d[:, 2], c=gt_color, s=100, \n",
    "                label='Ground Truth', depthshade=False)\n",
    "    for i, j in connections:\n",
    "        ax2.plot([gt_3d[i, 0], gt_3d[j, 0]], \n",
    "                 [gt_3d[i, 1], gt_3d[j, 1]], \n",
    "                 [gt_3d[i, 2], gt_3d[j, 2]], c=gt_color, linewidth=3)\n",
    "    \n",
    "    ax2.scatter(est_3d[:, 0], est_3d[:, 1], est_3d[:, 2], c=pred_color, s=100,\n",
    "                marker='x', label='Estimated (IK)', depthshade=False)\n",
    "    for i, j in connections:\n",
    "        ax2.plot([est_3d[i, 0], est_3d[j, 0]], \n",
    "                 [est_3d[i, 1], est_3d[j, 1]], \n",
    "                 [est_3d[i, 2], est_3d[j, 2]], c=pred_color, linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax2.set_xlabel('X (m)')\n",
    "    ax2.set_ylabel('Y (m)')\n",
    "    ax2.set_zlabel('Z (m)')\n",
    "    \n",
    "    add_err = df.loc[sample_idx, 'add_ik_cm'] if 'add_ik_cm' in df.columns else 0\n",
    "    ax2.set_title(f'3D Skeleton (ADD: {add_err:.1f} cm)')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    max_range = np.array([gt_3d[:, 0].max() - gt_3d[:, 0].min(),\n",
    "                          gt_3d[:, 1].max() - gt_3d[:, 1].min(),\n",
    "                          gt_3d[:, 2].max() - gt_3d[:, 2].min()]).max() / 2.0\n",
    "    mid_x = (gt_3d[:, 0].max() + gt_3d[:, 0].min()) * 0.5\n",
    "    mid_y = (gt_3d[:, 1].max() + gt_3d[:, 1].min()) * 0.5\n",
    "    mid_z = (gt_3d[:, 2].max() + gt_3d[:, 2].min()) * 0.5\n",
    "    ax2.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax2.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax2.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'add_ik_cm' in df.columns:\n",
    "    add_errors = df['add_ik_cm'].values\n",
    "    valid_mask = ~np.isnan(add_errors)\n",
    "    valid_indices = np.where(valid_mask)[0]\n",
    "    sorted_indices = valid_indices[np.argsort(add_errors[valid_indices])]\n",
    "    \n",
    "    samples_to_viz = {\n",
    "        'best': sorted_indices[0],\n",
    "        'median': sorted_indices[len(sorted_indices)//2],\n",
    "        'worst': sorted_indices[-1],\n",
    "    }\n",
    "    \n",
    "    for name, idx in samples_to_viz.items():\n",
    "        fig = visualize_prediction_3d(\n",
    "            idx, df, test_dataset,\n",
    "            save_path=FIGURES_DIR / f'sample_{name}.png'\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
